{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27445, 18)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = np.load('D_matrix.npy', mmap_mode='r')\n",
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "\n",
    "class BaseLabelPropagation:\n",
    "    '''Base class for label propagation models.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adj_matrix: torch.FloatTensor\n",
    "        Adjacency matrix of the graph.\n",
    "    '''\n",
    "    def __init__(self, adj_matrix):\n",
    "        self.norm_adj_matrix = self._normalize(adj_matrix)\n",
    "        self.n_nodes = adj_matrix.size(0)\n",
    "        self.one_hot_labels = None \n",
    "        self.n_classes = None\n",
    "        self.labeled_mask = None\n",
    "        self.predictions = None\n",
    "\n",
    "    @staticmethod\n",
    "    @abstractmethod\n",
    "    def _normalize(adj_matrix):\n",
    "        raise NotImplementedError('_normalize must be implemented')\n",
    "\n",
    "    @abstractmethod\n",
    "    def _propagate(self):\n",
    "        raise NotImplementedError('_propagate must be implemented')\n",
    "\n",
    "    def _one_hot_encode(self, labels):        \n",
    "        # Get the number of classes\n",
    "        classes = torch.arange(0, 11, device=labels.device)\n",
    "        classes = classes[classes != -1]\n",
    "        self.n_classes = classes.size(0)\n",
    "\n",
    "        # One-hot encode labeled data instances and zero rows corresponding to unlabeled instances\n",
    "        unlabeled_mask = (labels == -1)\n",
    "        #labels = labels.clone()  # defensive copying\n",
    "        labels[unlabeled_mask] = 0\n",
    "        self.one_hot_labels = torch.zeros((self.n_nodes, self.n_classes), dtype=torch.float, device=labels.device)\n",
    "        \n",
    "        self.one_hot_labels = self.one_hot_labels.scatter(1, labels.unsqueeze(1), 1)\n",
    "        self.one_hot_labels[unlabeled_mask, 0] = 0\n",
    "\n",
    "        self.labeled_mask = ~unlabeled_mask\n",
    "\n",
    "    def fit(self, labels, max_iter, tol, verbose=True):\n",
    "        '''Fits a semi-supervised learning label propagation model.\n",
    "        \n",
    "        labels: torch.LongTensor\n",
    "            Tensor of size n_nodes indicating the class number of each node.\n",
    "            Unlabeled nodes are denoted with -1.\n",
    "        max_iter: int\n",
    "            Maximum number of iterations allowed.\n",
    "        tol: float\n",
    "            Convergence tolerance: threshold to consider the system at steady state.\n",
    "        '''\n",
    "        self._one_hot_encode(labels)\n",
    "\n",
    "        self.predictions = self.one_hot_labels.clone()\n",
    "        prev_predictions = torch.zeros((self.n_nodes, self.n_classes), dtype=torch.float, device=labels.device)\n",
    "\n",
    "        for i in range(max_iter):\n",
    "            # Stop iterations if the system is considered at a steady state\n",
    "            variation = torch.abs(self.predictions - prev_predictions).sum().item()\n",
    "            \n",
    "            if variation < tol:\n",
    "                if verbose:\n",
    "                    print(f'The method stopped after {i} iterations, variation={variation:.4f}.')\n",
    "                break\n",
    "\n",
    "            prev_predictions = self.predictions.clone()\n",
    "            self._propagate()\n",
    "\n",
    "    def predict(self):\n",
    "        return self.predictions\n",
    "\n",
    "    def predict_classes(self):\n",
    "        return self.predictions.max(dim=1).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSpreading(BaseLabelPropagation):\n",
    "    def __init__(self, adj_matrix):\n",
    "        super().__init__(adj_matrix)\n",
    "        self.alpha = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize(adj_matrix):\n",
    "        '''Computes D^-1/2 * W * D^-1/2'''\n",
    "        degs = adj_matrix.sum(dim=1)\n",
    "        norm = torch.pow(degs, -0.5)\n",
    "        norm[torch.isinf(norm)] = 1\n",
    "        return adj_matrix * norm[:, None] * norm[None, :]\n",
    "\n",
    "    def _propagate(self):\n",
    "        self.predictions = (\n",
    "            self.alpha * torch.matmul(self.norm_adj_matrix, self.predictions)\n",
    "            + (1 - self.alpha) * self.one_hot_labels\n",
    "        )\n",
    "        #self.predictions[self.labeled_mask] = self.one_hot_labels[self.labeled_mask]\n",
    "    \n",
    "    def fit(self, labels, max_iter=1000, tol=1e-3, alpha=0.5, verbose=True):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha: float\n",
    "            Clamping factor.\n",
    "        '''\n",
    "        self.alpha = alpha\n",
    "        super().fit(labels, max_iter, tol, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def process_weight_matrix(W):\n",
    "    row_sums = W.sum(axis=1)\n",
    "    W /= row_sums[:, np.newaxis]\n",
    "\n",
    "    n = W.shape[0]\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                W[i, j] = max(W[i, j], W[j, i])\n",
    "    return W\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def generate_weight_matrix(n, p):\n",
    "    W = np.zeros(shape=(n, n), dtype=np.float32)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if np.random.uniform(0, 1) <= p:\n",
    "                W[i, j] = W[j, i] = 1.0\n",
    "\n",
    "    W = process_weight_matrix(W)\n",
    "    return W\n",
    "\n",
    "\n",
    "def initialize_population(population_len, n, p_range, n_jobs=-1):\n",
    "    population = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(generate_weight_matrix)(n, np.random.uniform(*p_range)) for _ in range(population_len)\n",
    "    )\n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_indices(data, test_size=0.3):\n",
    "    test_indices = []\n",
    "\n",
    "    for movie in data:\n",
    "        non_zero_indices = np.nonzero(movie)[0]\n",
    "\n",
    "        test_sample_size = int(test_size * len(non_zero_indices))\n",
    "\n",
    "        if test_sample_size > 0:\n",
    "            random_indices = np.random.choice(non_zero_indices, size=test_sample_size, replace=False)\n",
    "        else:\n",
    "            random_indices = []\n",
    "        \n",
    "        test_indices.append(random_indices)\n",
    "    \n",
    "    return test_indices\n",
    "\n",
    "\n",
    "def run_label_spreading(W, original_data, predicted_data, test_indices, alpha=0.8, verbose=True):\n",
    "    adj_matrix_t = torch.FloatTensor(W)\n",
    "\n",
    "    for i in range(original_data.shape[0]):\n",
    "        labels_t = torch.LongTensor( original_data[i, :W.shape[0]] )    # might need to make a copy of original_data for warning suppression\n",
    "        \n",
    "        if len(test_indices[i]):\n",
    "            labels_t[test_indices[i]] = 0\n",
    "        \n",
    "        labels_t[labels_t == 0] = -1\n",
    "            \n",
    "        label_spreading = LabelSpreading(adj_matrix_t)\n",
    "        label_spreading.fit(labels_t, alpha=alpha, verbose=verbose)\n",
    "        label_spreading_output_labels = label_spreading.predict_classes()\n",
    "\n",
    "        predicted_data[i, :] = label_spreading_output_labels\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def mean_absolute_error(y_true, y_pred, denom):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / denom\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def mean_squared_error(y_true, y_pred, denom):\n",
    "    return np.sum((y_true - y_pred) ** 2) / denom\n",
    "\n",
    "\n",
    "def get_loss(original_data, predicted_data, test_indices):\n",
    "    e = []\n",
    "\n",
    "    for i in range(original_data.shape[0]):\n",
    "        if len(test_indices[i]):\n",
    "            # print(len(test_indices[i]))\n",
    "            y_true = original_data[i, test_indices[i]].astype(np.int8)\n",
    "            y_pred = predicted_data[i, test_indices[i]].astype(np.int8)\n",
    "            # mae = mean_absolute_error(y_true, y_pred, len(original_data[i, :]) - np.count_nonzero(original_data[i, :]))\n",
    "            mse = mean_squared_error(y_true, y_pred, np.count_nonzero(original_data[i, :]))\n",
    "            e.append(mse)\n",
    "    \n",
    "    return -np.sum(e) / original_data.shape[0]\n",
    "\n",
    "\n",
    "def evaluate_population(population, original_data, verbose=True):\n",
    "    test_indices = get_test_indices(original_data)\n",
    "    scores = [ [i, None, None] for i in range(len(population)) ] \n",
    "\n",
    "    for i in range(len(population)):\n",
    "        # print(f'individual: {i}')\n",
    "        predicted_data = np.empty_like(original_data)\n",
    "        run_label_spreading(population[i], original_data, predicted_data, test_indices, verbose=verbose)\n",
    "        scores[i][1] = get_loss(original_data, predicted_data, test_indices)\n",
    "        scores[i][2] = predicted_data\n",
    "        \n",
    "    return scores\n",
    "\n",
    "\n",
    "def evaluate_individual(i, population, original_data, verbose=True):\n",
    "    test_indices = get_test_indices(original_data)\n",
    "    predicted_data = np.empty_like(original_data)\n",
    "    run_label_spreading(population[i], original_data, predicted_data, test_indices, verbose=verbose)\n",
    "    loss = get_loss(original_data, predicted_data, test_indices)\n",
    "    return [i, loss, predicted_data]\n",
    "\n",
    "\n",
    "def evaluate_population_parallel(population, original_data, verbose=True, n_jobs=-1):\n",
    "    scores = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(evaluate_individual)(i, population, original_data, verbose) for i in range(len(population))\n",
    "    )\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def crossover(W1, W2):\n",
    "    new_W = np.clip((W1 + W2) / 2, 0., 1.)\n",
    "    return process_weight_matrix(new_W)\n",
    "\n",
    "\n",
    "def elitist_selection(scores, elite_percentage):\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    elite_size = int(len(scores) * elite_percentage)\n",
    "    elites_indices = [ scores[i][0]  for i in range(elite_size) ]\n",
    "    return elites_indices\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "def tournament_selection(scores, elite_indices, num_parents, tournament_size):\n",
    "    parents_indices = elite_indices.copy()\n",
    "\n",
    "    len_updated = 0\n",
    "\n",
    "    while len(parents_indices) < num_parents:\n",
    "        tournament_indices = random.sample(range(len(scores)), tournament_size)\n",
    "        tournament_scores = [(i, scores[i][1]) for i in tournament_indices]\n",
    "\n",
    "        winner_idx = max(tournament_scores, key=lambda x: x[1])[0]\n",
    "        if winner_idx not in parents_indices:\n",
    "            parents_indices.append(winner_idx)\n",
    "            len_updated = 0\n",
    "        else:\n",
    "            len_updated += 1\n",
    "            if len_updated == 5:\n",
    "                parents_indices.append(winner_idx)\n",
    "    \n",
    "    return parents_indices \n",
    "\n",
    "\n",
    "def mutate_matrix(W, mutation_rate, mutation_range):\n",
    "    mutated_matrix = np.copy(W)\n",
    "    rows, cols = mutated_matrix.shape\n",
    "    num_mutations = int(np.ceil(mutation_rate * rows * cols))\n",
    "\n",
    "    mutation_indices = np.random.randint(0, rows * cols, num_mutations)\n",
    "    row_indices = mutation_indices // cols\n",
    "    col_indices = mutation_indices % cols\n",
    "\n",
    "    mutation_values = np.random.uniform(*mutation_range, num_mutations)\n",
    "\n",
    "    np.add.at(mutated_matrix, (row_indices, col_indices), mutation_values)\n",
    "    np.clip(mutated_matrix, 0.0, 1.0, out=mutated_matrix)\n",
    "\n",
    "    row_sums = mutated_matrix.sum(axis=1, keepdims=True)\n",
    "    mutated_matrix /= row_sums\n",
    "    mutated_matrix = (mutated_matrix + mutated_matrix.T) / 2\n",
    "\n",
    "    return mutated_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory_gb=47.835933685302734\n",
      "num_users=1372\n",
      "num_cpus=16\n",
      "partitions=15, population_len=25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psutil\n",
    "\n",
    "memory_gb = psutil.virtual_memory().total / 1024**3\n",
    "print(f'{memory_gb=}')\n",
    "\n",
    "num_users = int(0.05 * D.shape[0])\n",
    "print(f'{num_users=}')\n",
    "\n",
    "num_cpus = os.cpu_count()\n",
    "print(f'{num_cpus=}')\n",
    "\n",
    "partitions = num_cpus - 1\n",
    "population_len = 25\n",
    "print(f'{partitions=}, {population_len=}')\n",
    "p_range = (0.05, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 1372)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data = D.copy()[:num_users, :].T\n",
    "original_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_loss=-1.106072806456491, best_score=-0.951527806461808\n",
      "average_loss=-1.1618876178758089, best_score=-0.9401572957458245\n",
      "average_loss=-1.1151978849319701, best_score=-0.9840189601976618\n",
      "average_loss=-1.2655587152490884, best_score=-1.1136075561952359\n",
      "average_loss=-1.3666862314492223, best_score=-1.1625024738426584\n",
      "average_loss=-1.4780924309570576, best_score=-1.3694423197215453\n",
      "average_loss=-1.4239959940376998, best_score=-1.3900115933495534\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/george/Documents/projects/thesis/thesis/loop.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m population \u001b[39m=\u001b[39m initialize_population(population_len\u001b[39m=\u001b[39mpopulation_len, n\u001b[39m=\u001b[39mnum_users, p_range\u001b[39m=\u001b[39mp_range)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     scores \u001b[39m=\u001b[39m evaluate_population(population, original_data, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     valid_scores \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m scores \u001b[39mif\u001b[39;00m x[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mfinfo(\u001b[39mfloat\u001b[39m)\u001b[39m.\u001b[39mmax]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     average_loss \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(x[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m valid_scores) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(valid_scores)\n",
      "\u001b[1;32m/home/george/Documents/projects/thesis/thesis/loop.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(population)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     \u001b[39m# print(f'individual: {i}')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     predicted_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty_like(original_data)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     run_label_spreading(population[i], original_data, predicted_data, test_indices, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     scores[i][\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m get_loss(original_data, predicted_data, test_indices)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     scores[i][\u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m predicted_data\n",
      "\u001b[1;32m/home/george/Documents/projects/thesis/thesis/loop.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     labels_t[test_indices[i]] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m labels_t[labels_t \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m label_spreading \u001b[39m=\u001b[39m LabelSpreading(adj_matrix_t)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m label_spreading\u001b[39m.\u001b[39mfit(labels_t, alpha\u001b[39m=\u001b[39malpha, verbose\u001b[39m=\u001b[39mverbose)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m label_spreading_output_labels \u001b[39m=\u001b[39m label_spreading\u001b[39m.\u001b[39mpredict_classes()\n",
      "\u001b[1;32m/home/george/Documents/projects/thesis/thesis/loop.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, adj_matrix):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(adj_matrix)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/george/Documents/projects/thesis/thesis/loop.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, adj_matrix):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm_adj_matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_normalize(adj_matrix)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_nodes \u001b[39m=\u001b[39m adj_matrix\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/george/Documents/projects/thesis/thesis/loop.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mone_hot_labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "population = initialize_population(population_len=population_len, n=num_users, p_range=p_range)\n",
    "\n",
    "for i in range(epochs):\n",
    "    scores = evaluate_population(population, original_data, verbose=False)\n",
    "    valid_scores = [x for x in scores if x[1] != np.finfo(float).max]\n",
    "    average_loss = sum(x[1] for x in valid_scores) / len(valid_scores)\n",
    "\n",
    "    print(f'{average_loss=}, best_score={max(valid_scores, key=lambda x:x[1])[1]}')\n",
    "\n",
    "    elites_indices = elitist_selection(scores, 0.3)\n",
    "    parents_indices = tournament_selection(scores, elites_indices, population_len, int(0.3 * population_len))\n",
    "    parent_pairs = [(parents_indices[i], parents_indices[i + 1]) for i in range(0, len(parents_indices) - 1, 2)]\n",
    "    new_population = [ crossover(population[pair[0]], population[pair[1]]) for pair in parent_pairs ]\n",
    "    new_population.extend([ population[i] for i in parents_indices ])\n",
    "    population = [ mutate_matrix(new_population[i], mutation_rate=0.001, mutation_range=(-0.006, 0.006)) for i in range(len(new_population)) ]\n",
    "    # print(f'{len(elites_indices)=}, {len(parents_indices)=}, {len(parent_pairs)=}, {len(population)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_10_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
